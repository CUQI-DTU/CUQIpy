{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 05:  Solving differential equation-based Bayesian inverse problems using CUQIpy\n",
    "\n",
    "Here we build a Bayesian problem in which the forward model is a partial differential equation model, 1D Heat problem in particular.\n",
    "\n",
    "## Learning objectives of this notebook:\n",
    "- Solve PDE-based Bayesian problem in cuqi.\n",
    "- Parametrization of the Bayesian parameters (e.g. KL expansion, non-linear maps).\n",
    "- Introducing cuqi PDE class.\n",
    "\n",
    "## Table of contents: \n",
    "* [1. Loading the PDE test problem](#PDE_model)\n",
    "* [2. Building and solving the Bayesian inverse problem](#inverse_problem)\n",
    "* [3. Parametrizing the Bayesian parameters to enforce positivity](#mapped_geometries)\n",
    "* [4. (Optional) parametrizing the Bayesian parameters via step function expansion](#step_function)\n",
    "* [5. (Optional) elaboration: the PDEmodel class](#PDE_model_elaborate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Loading the PDE test problem <a class=\"anchor\" id=\"PDE_model\"></a>\n",
    "\n",
    "We first import the required python standard packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From cuqi package, we import the classes that we use in this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuqi.geometry import Continuous1D, MappedGeometry, KLExpansion\n",
    "from cuqi.pde import SteadyStateLinearPDE\n",
    "from cuqi.model import PDEModel\n",
    "from cuqi.distribution import GaussianCov, Posterior, Gaussian, Cauchy_diff\n",
    "from cuqi.sampler import CWMH, NUTS, pCN, MetropolisHastings\n",
    "from cuqi.testproblem import Heat_1D\n",
    "from cuqi.problem import BayesianProblem\n",
    "from cuqi.samples import CUQIarray\n",
    "from cuqi.operator import FirstOrderFiniteDifference\n",
    "from cuqi.pde import SteadyStateLinearPDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the load the test problem `Heat_1D` which provides a one dimensional (1D) time dependent heat model. The unknown Bayesian parameters for this model is the initial heat profile. The data are the temperature measurements everywhere in the domain at the final time step.\n",
    "\n",
    "We can explore the initialization parameters (and hence what can be passed to `get_components` method) of the `Heat_1D` test problem by calling `Heat_1D?`. We choose the following set up for the test problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heat_1D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50   # number of finite difference nodes            \n",
    "L = 1    # Length of the domain\n",
    "T = 0.2  # Final time\n",
    "\n",
    "model, data, problemInfo = Heat_1D.get_components(dim=N, endpoint=L, max_time=T, field_type = 'KL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at what we obtain from the test problem. We view the `model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we choose the domain geometry to be of type 'KL'. This will represent the initial heat profile in terms of KL expansion (try `KLExpansion?` for more information). \n",
    "$$ u(x) = \\sum_i p_i  (1/i)^{\\text{decay}}  sin(\\frac{i L x}{\\pi}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLExpansion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `problemInfo`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot the exact solution of this inverse problem and the exact and noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemInfo.exactSolution.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_exact_data = problemInfo.exactData.plot()\n",
    "l_noisy_data = data.plot()\n",
    "plt.legend([l_exact_data[0],l_noisy_data[0]] , ['exact data', 'noisy data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building and solving the Bayesian inverse problem <a class=\"anchor\" id=\"inverse_problem\"></a>\n",
    "\n",
    "Here we want to define the prior, the likelihood and the posterior distribution. We start by defining a prior random filed by discretizing a covariance function. The covariance function is defined as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 10\n",
    "lc = 0.2\n",
    "p = 2\n",
    "C_YY = lambda x1, x2: var*np.exp( -(1/p) * (abs( x1 - x2 )/lc)**p )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the prior, we discretize the correlation function to obtain the correlation matrix `sigma`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.domain_geometry.grid\n",
    "XX, YY = np.meshgrid(x, x, indexing='ij')\n",
    "sigma_prior = C_YY(XX, YY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the prior distribution as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "prior = GaussianCov(mean*np.ones(N), sigma_prior, geometry= model.domain_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Try yourself (optional)\n",
    "* create prior samples (~1 line).\n",
    "* plot the 95% confidence interval of the prior samples (~1 line).\n",
    "* look at the 95% confidence interval of the PDE model solution to quantify the forward uncertainty (~2 lines).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set up the likelihood. We obtain information about the noise distribution from `problemInfo.infoString`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 200\n",
    "sigma_likelihood = np.linalg.norm(problemInfo.exactData)/SNR\n",
    "likelihood = Gaussian(mean=model, std=sigma_likelihood, corrmat=np.eye(N), geometry=model.range_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the components we need, we can create the posterior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior =  Posterior(likelihood, prior, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now sample the posterior. Lets try component-wise Metropolis Hastings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySampler = pCN(posterior,1)\n",
    "posterior_samples,_ ,_ = MySampler.sample_adapt(10000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_ci(95, exact = problemInfo.exactSolution)\n",
    "print([posterior])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can look at the samples in the KL expansion coefficient space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.sample(500).plot_ci(95, plot_par = True, color = 'r')\n",
    "posterior_samples.plot_ci(95, plot_par = True, color = 'b')\n",
    "plt.xticks(np.arange(prior.dim)[::5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parametrizing the Bayesian parameters to enforce positivity <a class=\"anchor\" id=\"mapped_geometries\"></a> \n",
    "\n",
    "Here we introduce the concept of mapped geometries. In many inverse problems, parametrization of the forward model problem through possible nonlinear functions might be needed. For example, in this 1D heat example, we want to enforce positivity of the thermal conductivity. We can use the parametrization $c = e^\\kappa$ where $c$ is the thermal conductivity and $\\kappa$ is the Bayesian parameters.  \n",
    "\n",
    "In `CUQIpy`, this can be achieved through a `MappedGeometry` object. Lets update the exact solution, and the domain geometry and test this idea:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_exact_solution = np.log(problemInfo.exactSolution)\n",
    "KL_geometry = model.domain_geometry\n",
    "mapped_model = deepcopy(model)\n",
    "mapped_model.domain_geometry = MappedGeometry(KL_geometry, map = lambda x : np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We, again, build the posterior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_likelihood = Gaussian(mean=mapped_model, std=sigma_likelihood, corrmat=np.eye(N), geometry=model.range_geometry)\n",
    "mapped_posterior =  Posterior(mapped_likelihood, prior, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySampler2 = pCN(mapped_posterior,1)\n",
    "mapped_posterior_samples,_ ,_ = MySampler2.sample_adapt(10000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot the confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_posterior_samples.plot_ci(95, exact = problemInfo.exactSolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (Optional) parametrizing the Bayesian parameters via step function expansion <a class=\"anchor\" id=\"step_function\"></a>\n",
    "\n",
    "Here we explore a different parameterization, where the thermal conductivity is represented by a step function with 3 degrees of freedom. The code for this problem will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_model, step_data, step_problemInfo = Heat_1D.get_components(dim=N, endpoint=L, max_time=T, field_type = 'Step')\n",
    "step_prior = Gaussian(np.ones(3),1, geometry = step_model.domain_geometry)\n",
    "step_likelihood = Gaussian(mean=step_model, std=sigma_likelihood, corrmat=np.eye(N), geometry=model.range_geometry)\n",
    "step_posterior =  Posterior(step_likelihood, step_prior, step_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_samples.plot_ci(95, exact= np.log(step_problemInfo.exactSolution))\n",
    "\n",
    "step_problemInfo.exactSolution.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself:\n",
    "* You can try to use pCN sampler to generate, lets say 10000, posterior sample and view the 100% confidence interval (~3 lines). Use sample_adapt.\n",
    "* Try to enforce positivity of the posterior samples via the MappedGeometry and run the pCN sampler again (similar to part 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (Optional) elaboration: the PDEmodel class <a class=\"anchor\" id=\"PDE_model_elaborate\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore the model for PDE problems.\n",
    "\n",
    "Try it yourself:\n",
    "\n",
    "* View: `model`, `model.pde`, `model.pde.PDE_form`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create our own PDE model for simple wave poisson equation with zero boundaries for example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_poisson = 1000\n",
    "L = 1\n",
    "dx = L/(n_poisson-1)\n",
    "diff_operator = FirstOrderFiniteDifference(n_poisson,bc_type='zero').get_matrix().todense()/dx\n",
    "source_term = np.zeros(n_poisson)\n",
    "source_term[int(n_poisson/2)] = 1/dx \n",
    "\n",
    "poisson_form = lambda x: (diff_operator.T@diff_operator, x* source_term)\n",
    "CUQI_pde = SteadyStateLinearPDE(poisson_form)\n",
    "CUQI_pde.assemble(5)\n",
    "sol = CUQI_pde.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(dx,L,n_poisson,endpoint=False),sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it yourself:\n",
    "\n",
    "* Double the magnitude of the source term by editing the line `CUQI_pde.assemble(np.array([5]))` above. Look at the solution."
   ]
  }
 ],
 "metadata": {
  "language_info": {},
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}