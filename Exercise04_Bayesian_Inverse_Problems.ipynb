{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad78cad",
   "metadata": {},
   "source": [
    "# Exercise 04: Bayesian Inverse Problems\n",
    "\n",
    "In this notebook, we finally get started with Bayesian inverse problems. In particular, describe how to define a posterior distribution using CUQIpy and how to sample it.\n",
    "\n",
    "**Try to at least run through part 1 and 2 before working on the optional exercises**\n",
    "\n",
    "## Learning objectives\n",
    "* Define posterior distribution in CUQIpy.\n",
    "* Sample posterior distribution with specific choice of sampler and analyze results.\n",
    "* Compute point estimates of posterior, e.g., MAP or ML.\n",
    "* Describe how the high-level \"BayesianProblem\" combines the above steps into a convenient non-expert interface.\n",
    "\n",
    "## Table of contents\n",
    "1. [Defining the posterior distribution](#posterior)\n",
    "2. [Sampling the posterior](#sampling)\n",
    "3. [Computing point estimates of the posterior](#pointestimates) ★\n",
    "4. [Connection to BayesianProblem](#BayesianProbem) ★\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016eddd3",
   "metadata": {},
   "source": [
    "As we have seen a few times now, we start of by importing the Python packages we need (including CUQIpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cuqi\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdd109",
   "metadata": {},
   "source": [
    "## 1. Defining the posterior distribution TODO: math<a class=\"anchor\" id=\"posterior\"></a>\n",
    "\n",
    "In Bayesian Inverse problems the main thing of interest is the posterior distribution. In short, the posterior is defined (ignoring scaling constants) as the product of the prior and the likelihood distribution.\n",
    "\n",
    "Add back Posterior definition, keep it very short.\n",
    "$$d=A(\\theta),$$\n",
    "$$ p(x|d)\\propto p(d|x)p(x)$$\n",
    "**For example** in case of Gaussian...\n",
    "$$p(d|x)...$$\n",
    "$$p(x)...$$\n",
    "In the following, we see how these can easily be defined in CUQIpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968e40b",
   "metadata": {},
   "source": [
    "### Model and data\n",
    "Before defining the likelihood and prior, we first need an inverse problem to work with. For this example let us revisit the Deconvolution testproblem and extract a CUQIpy model and some data (in this case generated from the default phantom). Similar to earlier, we can also get additional information from the 3rd output argument (probInfo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "model, data, probInfo = cuqi.testproblem.Deconvolution.get_components(dim=n)\n",
    "probInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f7658",
   "metadata": {},
   "source": [
    "### Prior and likelihood TODO: Update text with new order\n",
    "The default phantom in the Deconvolution testproblem is well-represented by a Gaussian distribution and so let us define an i.i.d. Gaussian distribution as the prior (here the dimension is inferred from either the mean or the std)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = cuqi.distribution.Gaussian(mean=np.zeros(n), std=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b343c4",
   "metadata": {},
   "source": [
    "\n",
    "From the problem info string above, we see that the noise is additive Gaussian with std 0.05 and so the likelihood will also be Gaussian. Hence, as we already saw in exercise 03, defining the likelihood distribution is very simple in CUQIpy (the correct dimensions are automatically inferred from the model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = cuqi.distribution.Gaussian(mean=model, std=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efdd18",
   "metadata": {},
   "source": [
    "### Combine into posterior\n",
    "Once we have the likelihood, prior and an observed set of data we have all components to define the posterior distribution. This is then simply done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = cuqi.distribution.Posterior(likelihood, prior, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a146bbf",
   "metadata": {},
   "source": [
    "#### ★ Try yourself (optional):  \n",
    "The posterior is essentially just another CUQIpy distribution. Have a look at `posterior?` to see what attributes and methods are available. What happends if you call the `sample` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e76027",
   "metadata": {},
   "source": [
    "## 2. Sampling the posterior <a class=\"anchor\" id=\"sampling\"></a>\n",
    "In CUQIpy, we provide a number of samplers in the sampler module. All samplers have the same signature, namely\n",
    "`Sampler(target, ...)`, where `target` is the target CUQIpy distribution and `...` indicates any (optional) arguments.\n",
    "\n",
    "In the case of the posterior above which is defined from a linear model and Gaussian likelihood and prior, the Linear Randomize-then-Optimize (Linear_RTO) sampler is a good choice. Like any of the other samplers, we set-up the sampler by simply providing the target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = cuqi.sampler.Linear_RTO(posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536514b",
   "metadata": {},
   "source": [
    "and then running the sampler and storing the samples in the variable `samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937cbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05e1c5",
   "metadata": {},
   "source": [
    "Similar to directly sampling distributions in CUQIpy, when sampling using the sampler module the returned object is a `cuqi.samples.Samples` object. As we have already seen this object has a number of methods available. In this case, we are interested in evaluating if the sampling went well. To do this we can have a look at the chain history for 2 different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.plot_chain([30, 45]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa415d2",
   "metadata": {},
   "source": [
    "In both cases the chains look very good without much initial burn-in. This is in large part due to the Linear_RTO sampler. For the sake of presentation let us remove the first 100 samples using the `burnthin` method (see `samples.burnthin?`) and store the burnthinned samples in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae5d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_final = samples.burnthin(Nb=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5587f",
   "metadata": {},
   "source": [
    "Finally, we can plot a confidence interval of the samples and compare to the exact solution (from probInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad270c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_final.plot_ci(95, exact=probInfo.exactSolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b8d05",
   "metadata": {},
   "source": [
    "### Trying out other samples\n",
    "\n",
    "The Linear_RTO sampler can only sample Gaussian posteriors that also have an underlying linear model. It is possible to try out other CUQIpy samplers (which also work for a broader range of problems). For example:\n",
    "\n",
    "* **pCN** - Works OK with enough samples (>5000 in this case)\n",
    "* **CWMH** - Works OK with enough samples (>5000 in this case)\n",
    "* **NUTS** - A well established sampler in literature. Our implementation is still new and can be a little buggy and slow. Also NUTS requires gradients!\n",
    "\n",
    "#### ★ Try yourself (optional):  \n",
    "Try sampling the posterior above using the NUTS, CWMH or pCN sampler (see e.g. the help documentation for the sampler to get more info on it).\n",
    "\n",
    "Compare results (chain, confidence interval etc.) to the results from Linear_RTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf171b5",
   "metadata": {},
   "source": [
    "## 3 Computing point estimates of the posterior ★  <a class=\"anchor\" id=\"pointestimates\"></a>\n",
    "\n",
    "In Bayesian inverse problems one may also be interested in computing point estimates of the posterior, or perhaps even the likelihood. There are generally two ways to go about this 1) compute point estimates from the posterior samples and 2) compute point estimates using optimization-based methods.\n",
    "\n",
    "In this section, we are going to show-case the CUQIpy solver module aimed at computing point estimates using the second approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd9e07",
   "metadata": {},
   "source": [
    "### MAP estimation\n",
    "The Maxiumum a posteriori (MAP) estimate is equal to the mode of the posterior distribution, and can be computed by maximizing the pdf (or logpdf) of the posterior. Using the CUQIpy solver module this follows a similar flow to what we have seen before with one exception. In this case, we are forced to provide an initial guess. In this case we provide the initial guess as a CUQIarray with the posterior geometry, to allow for later plotting of the map estimate (this will most likely be handled automatically in future versions of CUQIpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a81f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = cuqi.samples.CUQIarray(np.zeros(n), geometry=posterior.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d594e",
   "metadata": {},
   "source": [
    "Given the initial guess, we simply set up a solver to maximize the logpdf of the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = cuqi.solver.maximize(posterior.logpdf, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d6309",
   "metadata": {},
   "source": [
    "With this we can simpy run the solve method to compute the MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map, info = MAP.solve()\n",
    "x_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd96f65",
   "metadata": {},
   "source": [
    "The info output argument contains some useful information to validate if the optimization went well or not. In this case we can check the convergence status and iteration number.\n",
    "\n",
    "*Note: Compared to the sampler module, in the solver module we have to resort to using a bit more \"Python lingo\" to get our desired results. This should indicate that this module is still at its early design-states*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info[\"message\"])\n",
    "print(\"Number of iterations: {}\".format(info[\"nit\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ecb90",
   "metadata": {},
   "source": [
    "#### Try yourself (optional):  \n",
    "If time permits, try playing around with the solver module. Suggested things to try:\n",
    "* Try computing the maximum mikelihood (ML) estimate. **Hint:** see `help(posterior.loglikelihood_function)`. What do you expect the ML estimate to look like?\n",
    "* By default the solver will use a numerical estimate of the gradient of the objective function. Can you find a way to pass the actual gradient? Did this increase the convergence speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9868bd",
   "metadata": {},
   "source": [
    "## 4. High-level interface (BayesianProblem) ★ <a class=\"anchor\" id=\"BayesianProblem\"></a>\n",
    "\n",
    "Finally, we make the connection to the \"BayesianProblem\" CUQIpy that we saw in exercise 01 for the non-expert interface. Essentially the BayesianProblem tries to conveniently wrap all of the steps we have seen earlier in this notebook into a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d69f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "BP = cuqi.problem.BayesianProblem(likelihood, prior, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d2603",
   "metadata": {},
   "source": [
    "For example, the `sample_posterior` method defines a posterior distribution (in the same way as we saw earlier), selects an appropriate CUQIpy sampler and runs the sampler. \n",
    "\n",
    "*The sampler selection is still work-in-progress and part of the CUQI project is to figure out which samplers are best suited for which inverse problems.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = BP.sample_posterior(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9382e9",
   "metadata": {},
   "source": [
    "Similar to distributions and samplers the BayesianProblem sample method returns a `cuqi.samples.Samples` object so we can e.g. plot the confidence interval easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.plot_ci(95,exact=probInfo.exactSolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6a8c6",
   "metadata": {},
   "source": [
    "MAP (and ML) estimates are also supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a46069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map = BP.MAP()\n",
    "x_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d233252",
   "metadata": {},
   "source": [
    "And finally, we return to the UQ method. Which wraps everything in a nice package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "BP.UQ(exact=probInfo.exactSolution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
