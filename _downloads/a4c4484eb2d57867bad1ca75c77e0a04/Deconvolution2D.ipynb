{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 2D Deconvolution\n\nIn this example we show how to quantify the uncertainty of a solution to a 2D deconvolution problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we import the modules needed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom cuqi.testproblem import Deconvolution2D\nfrom cuqi.distribution import Gaussian, LMRF\nfrom cuqi.problem import BayesianProblem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Deterministic model\n\nConsider the deterministic inverse problem\n\n\\begin{align}\\mathbf{y} = \\mathbf{A} \\mathbf{x}\\end{align}\n\nwhere $\\mathbf{A}$ is a matrix representing a 2D convolution operation and\n$\\mathbf{y}$ and $\\mathbf{x}$ are the data and unknown (solution to the inverse problem) respectively.\n\nA linear forward model like $\\mathbf{A}$ is represented by a :class:`~cuqi.model.LinearModel`\nand any data (like some observed data $\\mathbf{y}^\\mathrm{obs}$) as a :class:`~cuqi.array.CUQIarray`.\n\nThe easiest way to get these two components is to use the built-in testproblems.\nLet us extract the model and data for a 2D deconvolution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A, y_obs, info = Deconvolution2D().get_components()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Prior model\n\nNow we aim to represent our prior knowledge of the unknown image. In this case, let us assume\nthat the unknown is piecewise constant. This can be modelled by assuming a Laplace difference\nprior. The Laplace difference prior can be defined as\n\n\\begin{align}\\mathbf{x}_{i,j}-\\mathbf{x}_{i',j} \\sim \\mathrm{Laplace}(0, \\delta),\\\\\n  \\mathbf{x}_{i,j}-\\mathbf{x}_{i,j'} \\sim \\mathrm{Laplace}(0, \\delta),\\end{align}\n\nwhere $\\delta$ is the scale parameter defining how likely jumps from one pixel value\nto another are in the horizontal and vertical directions.\n\nThis distribution comes pre-defined in CUQIpy as the :class:`cuqi.distribution.LMRF`.\nNotice we have to specify the geometry of the unknown.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = LMRF(location=0, scale=0.1, geometry=A.domain_geometry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Likelihood model\n\nSuppose our data is corrupted by a Gaussian noise so our observational model is\n\n\\begin{align}\\mathbf{y}\\mid \\mathbf{x} \\sim \\mathcal{N}(\\mathbf{A} \\mathbf{x}, \\sigma^2),\\end{align}\n\nwhere $\\sigma^2$ is a noise variance that we know.\n\nWe can represent $\\mathbf{y}\\mid \\mathbf{x}$ as a :class:`cuqi.distribution.Distribution` object.\nWe often call the distribution of $\\mathbf{y}\\mid \\mathbf{x}$ the data distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = Gaussian(mean=A@x, cov=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Posterior sampling\nIn actuality we are interested in conditioning on the observed data $\\mathbf{y}^\\mathrm{obs}$,\nto obtain the posterior distribution\n\n\\begin{align}p(\\mathbf{x}|\\mathbf{y}^\\mathrm{obs}) \\propto p(\\mathbf{y}^\\mathrm{obs}|\\mathbf{x})p(\\mathbf{x}),\\end{align}\n\nand then sampling from this posterior distribution.\n\nIn CUQIpy, we the easiest way to do this is to use the :class:`cuqi.problem.BayesianProblem` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create Bayesian problem and set observed data (conditioning)\nBP = BayesianProblem(y, x).set_data(y=y_obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After setting the data, we can sample from the posterior using the :meth:`cuqi.problem.BayesianProblem.sample_posterior`\nmethod. Notice that a well-suited sampler is automatically chosen based on the model, likelihood and prior chosen.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Sample posterior\nsamples = BP.sample_posterior(200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Posterior analysis\n\nFinally, after sampling we can analyze the posterior. There are many options here. For example,\nwe can plot the credible intervals for the unknown image and compare it to the true image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = samples.plot_ci(exact=info.exactSolution)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}