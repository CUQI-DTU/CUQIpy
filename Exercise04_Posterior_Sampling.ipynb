{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad78cad",
   "metadata": {},
   "source": [
    "# Exercise 04: Bayesian Inverse Problems\n",
    "\n",
    "In this notebook, we finally get started with Bayesian inverse problems. In particular, describe how to define a posterior distribution using CUQIpy and how to sample it.\n",
    "\n",
    "**Try to run through parts 1 and 2 before working on the optional exercises**\n",
    "\n",
    "## Learning objectives\n",
    "* Define posterior distribution in CUQIpy.\n",
    "* Sample posterior distribution with specific choice of sampler and analyze results.\n",
    "* Compute point estimates of posterior, e.g., MAP or ML.\n",
    "* Describe how the high-level \"BayesianProblem\" combines the above steps into a convenient non-expert interface.\n",
    "\n",
    "## Table of contents\n",
    "1. [Defining the posterior distribution](#posterior)\n",
    "2. [Sampling the posterior](#sampling)\n",
    "3. [Computing point estimates of the posterior](#pointestimates) ★\n",
    "4. [Connection to BayesianProblem](#BayesianProbem) ★\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016eddd3",
   "metadata": {},
   "source": [
    "As we have seen a few times now, we start of by importing the Python packages we need (including CUQIpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cuqi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fdd109",
   "metadata": {},
   "source": [
    "## 1. Defining the posterior distribution <a class=\"anchor\" id=\"posterior\"></a>\n",
    "\n",
    "Solving a Bayesian inverse problem amounts to characterizing the so-called posterior distribution.\n",
    "In short, the posterior is defined (ignoring scaling constants) as the product of the prior and the likelihood.\n",
    "\n",
    "To elaborate, consider an inverse problem\n",
    "$$b=A(x)+e, \\quad b\\in\\mathbb{R}^m, \\, x\\in \\mathbb{R}^n,$$\n",
    "where $A: \\mathbb{R}^n \\to \\mathbb{R}^m$ is the forward model of the inverse problem and $e\\in\\mathbb{R}^m$ is additive measurement noise.\n",
    "\n",
    "The stochastic version (or Bayesian inverse problem) can then be written as\n",
    "\n",
    "$$B = A(X)+E,$$\n",
    "\n",
    "where $B$, $X$ and $E$ are random variables representing the stochastic nature of this interpretation of the problem.\n",
    "\n",
    "The posterior pdf is given by Bayes rule\n",
    "\n",
    "$$p(x|b)\\propto p(b|x)p(x),$$\n",
    "\n",
    "where $p(\\cdot)$ are probability density functions (pdfs). Here $p(b|x)$ describes the distribution of the data given $x$ and $p(x)$ the distribution of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5bbd93",
   "metadata": {},
   "source": [
    "### Posterior given a measurement (observation)\n",
    "\n",
    "In Bayesian inverse problems we are interested in $X$ given a single observation $b:=b^{obs}$. Hence in this context $p(b|x)$ can be viewed as a function of $x$ only. This is known as the likelihood function.\n",
    "\n",
    "To distinguish the likelihood from the data distribution, the following notation is used $L(x|b):=p(b|x)$. That is the likelihood $L(x|b): x\\mapsto p(b|x)$ is a function from $x$ to the value of the pdf $p(b|x)$ evaluated at the given $b$.\n",
    "\n",
    "Therefor given an observation $b=b^{obs}$ the posterior is given by\n",
    "\n",
    "$$p(x|b^{obs})\\propto L(x|b^{obs})p(x).$$\n",
    "\n",
    "The posterior describes the statistics of $x$ given the observation $b^{obs}$.\n",
    "\n",
    "**Example** in case of both Gaussian likelihood and prior with some assumed standard deviation and mean the likelihood and prior is given by\n",
    "\n",
    "$$L(x|b^{obs})\\propto \\exp\\left(-\\frac{1}{2 \\sigma^2}\\|b^{obs}-A(x)\\|_2^2\\right),$$\n",
    "\n",
    "$$p(x)\\propto \\exp\\left(-\\frac{1}{2 \\delta^2}\\|x-\\mu_x\\|_2^2\\right).$$\n",
    "\n",
    "\n",
    "\n",
    "In the following, we see how the posterior can be defined in CUQIpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968e40b",
   "metadata": {},
   "source": [
    "### Model and data\n",
    "Before defining the likelihood and prior (which are needed for the posterior) we first need an inverse problem to work with.\n",
    "\n",
    "For this example let us revisit the Deconvolution testproblem and extract a CUQIpy model and some data (in this case generated from the default phantom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "model, data, probInfo = cuqi.testproblem.Deconvolution1D.get_components(dim=n)\n",
    "probInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f7658",
   "metadata": {},
   "source": [
    "### Prior and likelihood\n",
    "The default phantom in the Deconvolution testproblem is well-represented by a Gaussian distribution and so let us define an i.i.d. Gaussian distribution as the prior (here the dimension is inferred from either the mean or the std)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = cuqi.distribution.Gaussian(mean=np.zeros(n), std=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b343c4",
   "metadata": {},
   "source": [
    "\n",
    "From the problem info string above, we see that the noise is additive Gaussian with std 0.05 and so the data distribution $p(b|x)$ will also follow a Gaussian distribution (as seen in exercise 03):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dist = cuqi.distribution.Gaussian(mean=model, std=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a8dec",
   "metadata": {},
   "source": [
    "To arrive at the likelihood we simply need to convert this distribution to a likelihood function given the observed data. In CUQIpy this is achieved as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = data_dist.to_likelihood(data) #Here data is the observed data (b^obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6802fe",
   "metadata": {},
   "source": [
    "Very often the intermediate step of defining the data distribution is not needed and the likelihood can be defined in one line as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f66713",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = cuqi.distribution.Gaussian(mean=model, std=0.05).to_likelihood(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efdd18",
   "metadata": {},
   "source": [
    "### Combine into posterior\n",
    "Once we have the likelihood and prior, we have all components to define the posterior distribution. This is then simply done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = cuqi.distribution.Posterior(likelihood, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a146bbf",
   "metadata": {},
   "source": [
    "#### ★ Try yourself (optional):  \n",
    "The posterior is essentially just another CUQIpy distribution. Have a look at `posterior?` to see what attributes and methods are available. What happends if you call the `sample` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e76027",
   "metadata": {},
   "source": [
    "## 2. Sampling the posterior <a class=\"anchor\" id=\"sampling\"></a>\n",
    "In CUQIpy, we provide a number of samplers in the sampler module. All samplers have the same signature, namely\n",
    "`Sampler(target, ...)`, where `target` is the target CUQIpy distribution and `...` indicates any (optional) arguments.\n",
    "\n",
    "In the case of the posterior above which is defined from a linear model and Gaussian likelihood and prior, the Linear Randomize-then-Optimize (Linear_RTO) sampler is a good choice. Like any of the other samplers, we set-up the sampler by simply providing the target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = cuqi.sampler.Linear_RTO(posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536514b",
   "metadata": {},
   "source": [
    "and then running the sampler and storing the samples in the variable `samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937cbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.sample(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05e1c5",
   "metadata": {},
   "source": [
    "Similar to directly sampling distributions in CUQIpy, when sampling using the sampler module the returned object is a `cuqi.samples.Samples` object. As we have already seen this object has a number of methods available. In this case, we are interested in evaluating if the sampling went well. To do this we can have a look at the chain history for 2 different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.plot_chain([30, 45]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa415d2",
   "metadata": {},
   "source": [
    "In both cases the chains look very good without much initial burn-in. This is in large part due to the Linear_RTO sampler. For the sake of presentation let us remove the first 100 samples using the `burnthin` method (see `samples.burnthin?`) and store the burnthinned samples in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae5d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_final = samples.burnthin(Nb=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5587f",
   "metadata": {},
   "source": [
    "Finally, we can plot a credibility interval of the samples and compare to the exact solution (from probInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad270c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_final.plot_ci(95, exact=probInfo.exactSolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b8d05",
   "metadata": {},
   "source": [
    "### Trying out other samples\n",
    "\n",
    "The Linear_RTO sampler can only sample Gaussian posteriors that also have an underlying linear model. It is possible to try out other CUQIpy samplers (which also work for a broader range of problems). For example:\n",
    "\n",
    "* **pCN** - Works OK with enough samples (>5000 in this case)\n",
    "* **CWMH** - Works OK with enough samples (>5000 in this case)\n",
    "* **NUTS** - A well established sampler in literature. Also NUTS requires gradients!\n",
    "\n",
    "#### ★ Try yourself (optional):  \n",
    "Try sampling the posterior above using the NUTS, CWMH or pCN sampler (see e.g. the help documentation for the sampler to get more info on it).\n",
    "\n",
    "Compare results (chain, credibility interval etc.) to the results from Linear_RTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016cbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf171b5",
   "metadata": {},
   "source": [
    "## 3 Computing point estimates of the posterior ★  <a class=\"anchor\" id=\"pointestimates\"></a>\n",
    "\n",
    "In Bayesian inverse problems one may also be interested in computing point estimates of the posterior, or perhaps even the likelihood. There are generally two ways to go about this 1) compute point estimates from the posterior samples and 2) compute point estimates using optimization-based methods.\n",
    "\n",
    "In this section, we are going to show-case the CUQIpy solver module aimed at computing point estimates using the second approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd9e07",
   "metadata": {},
   "source": [
    "### MAP estimation\n",
    "The Maxiumum a posteriori (MAP) estimate is equal to the mode of the posterior distribution, and can be computed by maximizing the pdf (or logpdf) of the posterior. Using the CUQIpy solver module this follows a similar flow to what we have seen before with one exception. In this case, we are forced to provide an initial guess. In this case we provide the initial guess as a CUQIarray with the posterior geometry, to allow for later plotting of the map estimate (this will most likely be handled automatically in future versions of CUQIpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a81f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = cuqi.samples.CUQIarray(np.zeros(n), geometry=posterior.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d594e",
   "metadata": {},
   "source": [
    "Given the initial guess, we simply set up a solver to maximize the logpdf of the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = cuqi.solver.maximize(posterior.logpdf, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d6309",
   "metadata": {},
   "source": [
    "With this we can simpy run the solve method to compute the MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map, info = MAP.solve()\n",
    "x_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd96f65",
   "metadata": {},
   "source": [
    "The info output argument contains some useful information to validate if the optimization went well or not. In this case we can check the convergence status and iteration number.\n",
    "\n",
    "*Note: Compared to the sampler module, in the solver module we have to resort to using a bit more \"Python lingo\" to get our desired results. This should indicate that this module is still at its early design-states*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info[\"message\"])\n",
    "print(\"Number of iterations: {}\".format(info[\"nit\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ecb90",
   "metadata": {},
   "source": [
    "#### Try yourself (optional):  \n",
    "If time permits, try playing around with the solver module. Suggested things to try:\n",
    "* Try computing the maximum likelihood (ML) estimate. What do you expect the ML estimate to look like?\n",
    "* By default the solver will use a numerical estimate of the gradient of the objective function. Can you find a way to pass the actual gradient? Did this increase the convergence speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9868bd",
   "metadata": {},
   "source": [
    "## 4. High-level interface (BayesianProblem) ★ <a class=\"anchor\" id=\"BayesianProblem\"></a>\n",
    "\n",
    "Finally, we make the connection to the \"BayesianProblem\" CUQIpy that we saw in exercise 01 for the non-expert interface. Essentially the BayesianProblem tries to conveniently wrap all of the steps we have seen earlier in this notebook into a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d69f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "BP = cuqi.problem.BayesianProblem(likelihood, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d2603",
   "metadata": {},
   "source": [
    "For example, the `sample_posterior` method defines a posterior distribution (in the same way as we saw earlier), selects an appropriate CUQIpy sampler and runs the sampler. \n",
    "\n",
    "*The sampler selection is still work-in-progress and part of the CUQI project is to figure out which samplers are best suited for which inverse problems.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = BP.sample_posterior(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9382e9",
   "metadata": {},
   "source": [
    "Similar to distributions and samplers the BayesianProblem sample method returns a `cuqi.samples.Samples` object so we can e.g. plot the credibility interval easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.plot_ci(95,exact=probInfo.exactSolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6a8c6",
   "metadata": {},
   "source": [
    "MAP (and ML) estimates are also supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a46069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_map = BP.MAP()\n",
    "x_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d233252",
   "metadata": {},
   "source": [
    "And finally, we return to the UQ method. Which wraps everything in a nice package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "BP.UQ(exact=probInfo.exactSolution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
